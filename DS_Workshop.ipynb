{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data libraries.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# Data vizualization libraries.\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Association rules libraries.\n",
    "from efficient_apriori import apriori\n",
    "\n",
    "# Machine learning libraries.\n",
    "import datawig\n",
    "\n",
    "# Utilities we wrote for this project.\n",
    "import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>observation-weight</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>11th</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302.0</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927.0</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>United-States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age          workclass  observation-weight    education  \\\n",
       "0      39.0          State-gov             77516.0    Bachelors   \n",
       "1      50.0   Self-emp-not-inc             83311.0    Bachelors   \n",
       "2      38.0            Private            215646.0      HS-grad   \n",
       "3      53.0            Private            234721.0         11th   \n",
       "4      28.0            Private            338409.0    Bachelors   \n",
       "...     ...                ...                 ...          ...   \n",
       "32556  27.0            Private            257302.0   Assoc-acdm   \n",
       "32557   NaN            Private            154374.0      HS-grad   \n",
       "32558  58.0            Private            151910.0      HS-grad   \n",
       "32559  22.0            Private            201490.0      HS-grad   \n",
       "32560   NaN       Self-emp-inc            287927.0      HS-grad   \n",
       "\n",
       "       education-num       marital-status          occupation    relationship  \\\n",
       "0                NaN        Never-married        Adm-clerical   Not-in-family   \n",
       "1               13.0   Married-civ-spouse     Exec-managerial         Husband   \n",
       "2                NaN                  NaN   Handlers-cleaners   Not-in-family   \n",
       "3                7.0   Married-civ-spouse   Handlers-cleaners         Husband   \n",
       "4               13.0   Married-civ-spouse      Prof-specialty            Wife   \n",
       "...              ...                  ...                 ...             ...   \n",
       "32556           12.0   Married-civ-spouse        Tech-support            Wife   \n",
       "32557            9.0   Married-civ-spouse   Machine-op-inspct         Husband   \n",
       "32558            9.0              Widowed        Adm-clerical             NaN   \n",
       "32559            NaN        Never-married        Adm-clerical       Own-child   \n",
       "32560            9.0                  NaN     Exec-managerial            Wife   \n",
       "\n",
       "         race      sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       White      NaN        2174.0           0.0            40.0   \n",
       "1       White     Male           0.0           0.0            13.0   \n",
       "2       White     Male           0.0           NaN            40.0   \n",
       "3       Black     Male           0.0           0.0            40.0   \n",
       "4       Black   Female           NaN           0.0            40.0   \n",
       "...       ...      ...           ...           ...             ...   \n",
       "32556   White   Female           0.0           0.0            38.0   \n",
       "32557   White     Male           0.0           0.0            40.0   \n",
       "32558   White   Female           0.0           0.0            40.0   \n",
       "32559   White      NaN           0.0           0.0            20.0   \n",
       "32560   White   Female       15024.0           0.0            40.0   \n",
       "\n",
       "       native-country   class  \n",
       "0       United-States   <=50K  \n",
       "1       United-States   <=50K  \n",
       "2                 NaN   <=50K  \n",
       "3       United-States   <=50K  \n",
       "4                Cuba   <=50K  \n",
       "...               ...     ...  \n",
       "32556             NaN   <=50K  \n",
       "32557   United-States    >50K  \n",
       "32558   United-States   <=50K  \n",
       "32559   United-States   <=50K  \n",
       "32560   United-States     NaN  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from files.\n",
    "df = pd.read_csv('./data/adultsIncome/raw/raw_adultsIncome_no_nan.csv')\n",
    "df_with_missing = pd.read_csv('./data/adultsIncome/10percent/raw_adultsIncome_0.1nan.csv')\n",
    "df_with_missing_ar = df_with_missing.copy()\n",
    "df_with_missing_ml = df_with_missing.copy()\n",
    "df_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values: 25263\n"
     ]
    }
   ],
   "source": [
    "num_of_missing_before = df_with_missing_ar.isna().any(axis=1).sum()\n",
    "print(f'Number of missing values: {num_of_missing_before}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules algorithm to fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_apriori = df_with_missing_ar.copy()\n",
    "\n",
    "# go through each column and replace the values with a string\n",
    "for col in df_for_apriori.columns:\n",
    "    df_for_apriori[col] = df_for_apriori[col].astype(str)\n",
    "# convert the dataframe to a list of lists\n",
    "dict_for_apriori = df_for_apriori.to_dict(orient='records')\n",
    "transactions = [list(item.items()) for item in dict_for_apriori]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the association rules using the Apriori algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 311 rules and here are the first 10:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{('capital-loss', '0.0')} -> {('capital-gain', '0.0')},\n",
       " {('capital-gain', '0.0')} -> {('capital-loss', '0.0')},\n",
       " {('class', ' <=50K')} -> {('capital-gain', '0.0')},\n",
       " {('capital-gain', '0.0')} -> {('class', ' <=50K')},\n",
       " {('hours-per-week', '40.0')} -> {('capital-gain', '0.0')},\n",
       " {('marital-status', ' Married-civ-spouse')} -> {('capital-gain', '0.0')},\n",
       " {('native-country', ' United-States')} -> {('capital-gain', '0.0')},\n",
       " {('capital-gain', '0.0')} -> {('native-country', ' United-States')},\n",
       " {('race', ' White')} -> {('capital-gain', '0.0')},\n",
       " {('capital-gain', '0.0')} -> {('race', ' White')}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemsets, rules = apriori(transactions, min_support=0.3, min_confidence=0.6, output_transaction_ids=False)\n",
    "print(f'We have {len(rules)} rules and here are the first 10:')\n",
    "rules[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule: (('relationship', ' Husband'),) -> (('marital-status', ' Married-civ-spouse'),), Lift: 2.1704298119741976\n",
      "Rule: (('marital-status', ' Married-civ-spouse'),) -> (('relationship', ' Husband'),), Lift: 2.1704298119741976\n",
      "Rule: (('relationship', ' Husband'),) -> (('sex', ' Male'),), Lift: 1.4940869263906227\n",
      "Rule: (('marital-status', ' Married-civ-spouse'),) -> (('sex', ' Male'),), Lift: 1.3249761103300426\n",
      "Rule: (('class', ' <=50K'), ('race', ' White')) -> (('capital-gain', '0.0'), ('capital-loss', '0.0'), ('native-country', ' United-States')), Lift: 1.0913095646708846\n",
      "Rule: (('capital-gain', '0.0'), ('capital-loss', '0.0'), ('workclass', ' Private')) -> (('class', ' <=50K'),), Lift: 1.0885235124178607\n",
      "Rule: (('class', ' <=50K'), ('workclass', ' Private')) -> (('capital-gain', '0.0'), ('capital-loss', '0.0')), Lift: 1.0747848688333201\n",
      "Rule: (('class', ' <=50K'), ('native-country', ' United-States')) -> (('capital-gain', '0.0'), ('capital-loss', '0.0')), Lift: 1.0710700712799093\n",
      "Rule: (('capital-gain', '0.0'), ('workclass', ' Private')) -> (('capital-loss', '0.0'), ('class', ' <=50K')), Lift: 1.0705179753390623\n",
      "Rule: (('capital-gain', '0.0'), ('capital-loss', '0.0')) -> (('class', ' <=50K'),), Lift: 1.0701395354848702\n"
     ]
    }
   ],
   "source": [
    "# sort rules by lift value\n",
    "sorted_rules = sorted(rules, key=lambda x: x.lift, reverse=True)\n",
    "for rule in sorted_rules[:10]:\n",
    "    print(f'Rule: {rule.lhs} -> {rule.rhs}, Lift: {rule.lift}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_index_rows = df_with_missing_ar.index[df_with_missing_ar.isna().any(axis=1)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|â–ˆâ–ˆâ–ˆ       | 7894/25263 [00:23<00:52, 332.43it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[39mif\u001b[39;00m should_fill:\n\u001b[0;32m     33\u001b[0m     \u001b[39mfor\u001b[39;00m keyval \u001b[39min\u001b[39;00m rule\u001b[39m.\u001b[39mrhs:\n\u001b[1;32m---> 34\u001b[0m         df_with_missing\u001b[39m.\u001b[39;49miloc[index,col_names_dict[keyval[\u001b[39m0\u001b[39;49m]]] \u001b[39m=\u001b[39m keyval[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hex\\Desktop\\DataTablesProject\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[1;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Hex\\Desktop\\DataTablesProject\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1792\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[0;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[0;32m   1794\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[1;32m-> 1795\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1796\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[1;32mc:\\Users\\Hex\\Desktop\\DataTablesProject\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1888\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1884\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1885\u001b[0m \n\u001b[0;32m   1886\u001b[0m     \u001b[39m# scalar value\u001b[39;00m\n\u001b[0;32m   1887\u001b[0m     \u001b[39mfor\u001b[39;00m loc \u001b[39min\u001b[39;00m ilocs:\n\u001b[1;32m-> 1888\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_single_column(loc, value, pi)\n",
      "File \u001b[1;32mc:\\Users\\Hex\\Desktop\\DataTablesProject\\.venv\\lib\\site-packages\\pandas\\core\\indexing.py:1992\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[1;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[0;32m   1988\u001b[0m         value \u001b[39m=\u001b[39m value[pi]\n\u001b[0;32m   1989\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1990\u001b[0m     \u001b[39m# set value into the column (first attempting to operate inplace, then\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m     \u001b[39m#  falling back to casting if necessary)\u001b[39;00m\n\u001b[1;32m-> 1992\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mcolumn_setitem(loc, plane_indexer, value)\n\u001b[0;32m   1993\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_clear_item_cache()\n\u001b[0;32m   1994\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hex\\Desktop\\DataTablesProject\\.venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1392\u001b[0m, in \u001b[0;36mBlockManager.column_setitem\u001b[1;34m(self, loc, idx, value, inplace)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1391\u001b[0m     new_mgr \u001b[39m=\u001b[39m col_mgr\u001b[39m.\u001b[39msetitem((idx,), value)\n\u001b[1;32m-> 1392\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miset(loc, new_mgr\u001b[39m.\u001b[39;49m_block\u001b[39m.\u001b[39;49mvalues, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Hex\\Desktop\\DataTablesProject\\.venv\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1245\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[1;34m(self, loc, value, inplace)\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[39m# Accessing public blknos ensures the public versions are initialized\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m blknos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblknos[loc]\n\u001b[1;32m-> 1245\u001b[0m blklocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblklocs[loc]\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m   1247\u001b[0m unfit_mgr_locs \u001b[39m=\u001b[39m []\n\u001b[0;32m   1248\u001b[0m unfit_val_locs \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create a dictionary with the column names and the index of the column\n",
    "col_names = df_with_missing_ar.columns\n",
    "col_names_dict = {}\n",
    "for i, col in enumerate(col_names):\n",
    "    col_names_dict[col] = i\n",
    "\n",
    "\n",
    "# algortihm to fill missing values\n",
    "for index in tqdm(df_missing_index_rows):\n",
    "    # print the current row on the same line (replacing the previous line)\n",
    "    row = df_with_missing_ar.iloc[index]\n",
    "    rhs = []\n",
    "    lhs = [] \n",
    "    for col in row.index:\n",
    "        if row[col] != row[col]:\n",
    "            rhs.append(col)\n",
    "        else:\n",
    "            lhs.append(col)\n",
    "    relevant_rules = []\n",
    "    for rule in sorted_rules:\n",
    "        # check if [col[0] for col in rule.rhs] is a subset of rhs\n",
    "        if set([col[0] for col in rule.rhs]).issubset(set(rhs)):\n",
    "            relevant_rules.append(rule)\n",
    "    for rule in relevant_rules:\n",
    "        # check if [keyval[0] for keyval in rule.lhs] is a subset of lhs\n",
    "        if set([keyval for keyval in rule.lhs]).issubset(set([(col, row[col]) for col in lhs])):\n",
    "            should_fill = True\n",
    "            for keyval in rule.rhs:\n",
    "                if row[keyval[0]] == row[keyval[0]] and keyval[1] != row[keyval[0]]:\n",
    "                    should_fill = False\n",
    "                    break       \n",
    "            if should_fill:\n",
    "                for keyval in rule.rhs:\n",
    "                    df_with_missing_ar.iloc[index,col_names_dict[keyval[0]]] = keyval[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8544\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16719"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_missing_after = df_with_missing_ar.isna().any(axis=1).sum()\n",
    "print(f'Number of filled values: {num_of_missing_before- num_of_missing_after}')\n",
    "print(f'Number of left missing values: {num_of_missing_after}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With NaN = 33.78376994973531\n",
      " Without NaN = 79.0672462834755\n"
     ]
    }
   ],
   "source": [
    "print(f'With NaN = {utils.check_accuracy(df,df_with_missing_ar,0.1,True)}%')\n",
    "print(f'Without NaN = {utils.check_accuracy(df,df_with_missing_ar,0.1,False)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning algorithm to fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values using datawig.\n",
    "df_with_missing_imputed = datawig.SimpleImputer.complete(df_with_missing_ml, precision_threshold = 0.05, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'With NaN = {utils.check_accuracy(df, df_with_missing_imputed, 0.1, True)}%')\n",
    "print(f'Without NaN = {utils.check_accuracy(df, df_with_missing_imputed, 0.1, False)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D, E, F, G\n",
    "# A -> B\n",
    "# A -> D\n",
    "# A:1 -> D:4\n",
    "# A, B, C -> D, E\n",
    "# A:1, B:2, C:3 -> D:5, E:6\n",
    "# Impute missing values using datawig.\n",
    "# df_with_missing_imputed = datawig.SimpleImputer.complete(df_with_missing, precision_threshold = 0.05, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_with_missing.isna().sum().sum())\n",
    "# print(df_with_missing_imputed.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'With Nan = {check_accuracy(df, df_with_missing_imputed, True)}\\n Without Nan = {check_accuracy(df, df_with_missing_imputed, False)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9fe82780df2aa147e62ba0f4442bd6b9167435ab2261ee644cb1d0ee281d9178"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
